{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Introduction\n",
    "\n",
    "---\n",
    "\n",
    "For this project, we are going to work on evaluating price of houses given the following features:\n",
    "\n",
    "1. Year of sale of the house\n",
    "2. The age of the house at the time of sale\n",
    "3. Distance from city center\n",
    "4. Number of stores in the locality\n",
    "5. The latitude\n",
    "6. The longitude\n",
    "\n",
    "![Regression](gambar/regression.png)\n",
    "\n",
    "Note: This notebook uses `python 3` and these packages: `tensorflow`, `pandas`, `matplotlib`, `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Importing Libraries & Helper Functions\n",
    "\n",
    "First of all, we will need to import some libraries and helper functions. This includes TensorFlow and some utility functions that I've written to save time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di bawah ini digunakan karena ketika langsung import modul, muncul <a href=\"https://stackoverflow.com/questions/54843067/no-module-named-torch\">'no module named torch'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::pandas==1.0.1=py36h0573a6f_0\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::scikit-learn==0.22.1=py36hd81dba3_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::bkcharts==0.2=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/linux-64::pytest-arraydiff==0.3=py36h39e3cac_0\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py36heb32a55_0\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py36h7b6447c_0\n",
      "  - defaults/noarch::pytest-astropy==0.8.0=py_0\n",
      "  - defaults/linux-64::numexpr==2.7.1=py36h423224d_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/linux-64::h5py==2.10.0=py36h7918eee_0\n",
      "  - defaults/linux-64::bokeh==1.4.0=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::numpy-base==1.18.1=py36hde5b4d6_1\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::astropy==4.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::patsy==0.5.1=py36_0\n",
      "  - defaults/linux-64::scikit-image==0.16.2=py36h0573a6f_0\n",
      "  - defaults/linux-64::matplotlib-base==3.1.3=py36hef1b27d_0\n",
      "  - defaults/linux-64::imageio==2.6.1=py36_0\n",
      "  - defaults/linux-64::pytables==3.6.1=py36h71ec239_0\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::mkl_fft==1.0.15=py36ha843d7b_0\n",
      "  - defaults/linux-64::statsmodels==0.11.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/noarch::seaborn==0.10.0=py_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/linux-64::numba==0.48.0=py36h0573a6f_0\n",
      "  - defaults/linux-64::scipy==1.4.1=py36h0b6359f_0\n",
      "  - defaults/noarch::pytest-doctestplus==0.5.0=py_0\n",
      "  - defaults/linux-64::mkl_random==1.1.0=py36hd6b4f25_0\n",
      "  - defaults/noarch::dask==2.11.0=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::matplotlib==3.1.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "  - defaults/linux-64::numpy==1.18.1=py36h4f9e942_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/linux-64::bokeh==1.4.0=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::scikit-image==0.16.2=py36h0573a6f_0\n",
      "  - defaults/linux-64::imageio==2.6.1=py36_0\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/noarch::dask==2.11.0=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-cpu\n",
      "    - torchvision-cpu\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    astroid-2.4.2              |   py36h9f0ad1d_1         297 KB  conda-forge\n",
      "    boto3-1.16.38              |     pyhd8ed1ab_0          70 KB  conda-forge\n",
      "    botocore-1.19.38           |     pyhd8ed1ab_0         4.4 MB  conda-forge\n",
      "    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n",
      "    certifi-2020.12.5          |   py36h5fab9bb_0         143 KB  conda-forge\n",
      "    docutils-0.16              |   py36h5fab9bb_2         734 KB  conda-forge\n",
      "    pillow-7.1.2               |   py36hb39fc2d_0         604 KB\n",
      "    pylint-2.6.0               |   py36h9f0ad1d_1         446 KB  conda-forge\n",
      "    pytorch-cpu-1.1.0          |      py3.6_cpu_0        53.5 MB  pytorch\n",
      "    s3transfer-0.3.3           |     pyhd8ed1ab_5          51 KB  conda-forge\n",
      "    sphinx-3.3.1               |     pyhd8ed1ab_1         1.5 MB  conda-forge\n",
      "    toml-0.10.2                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    torchvision-cpu-0.3.0      |    py36_cuNone_1         3.8 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        65.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  astroid            conda-forge/linux-64::astroid-2.4.2-py36h9f0ad1d_1\n",
      "  bleach             conda-forge/noarch::bleach-3.2.1-pyh9f0ad1d_0\n",
      "  boto3              conda-forge/noarch::boto3-1.16.38-pyhd8ed1ab_0\n",
      "  botocore           conda-forge/noarch::botocore-1.19.38-pyhd8ed1ab_0\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py36he6145b8_1001\n",
      "  docutils           conda-forge/linux-64::docutils-0.16-py36h5fab9bb_2\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.1-hfc4b9b4_2\n",
      "  pillow             pkgs/main/linux-64::pillow-7.1.2-py36hb39fc2d_0\n",
      "  pylint             conda-forge/linux-64::pylint-2.6.0-py36h9f0ad1d_1\n",
      "  pytorch-cpu        pytorch/linux-64::pytorch-cpu-1.1.0-py3.6_cpu_0\n",
      "  s3transfer         conda-forge/noarch::s3transfer-0.3.3-pyhd8ed1ab_5\n",
      "  sphinx             conda-forge/noarch::sphinx-3.3.1-pyhd8ed1ab_1\n",
      "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n",
      "  torchvision-cpu    pytorch/linux-64::torchvision-cpu-0.3.0-py36_cuNone_1\n",
      "  urllib3            conda-forge/noarch::urllib3-1.25.11-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2020.6.20-hecda079_0 --> 2020.12.5-ha878542_0\n",
      "  certifi                          2020.6.20-py36h9880bd3_2 --> 2020.12.5-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "botocore-1.19.38     | 4.4 MB    | ##################################### | 100% \n",
      "certifi-2020.12.5    | 143 KB    | ##################################### | 100% \n",
      "pillow-7.1.2         | 604 KB    | ##################################### | 100% \n",
      "pytorch-cpu-1.1.0    | 53.5 MB   | ##################################### | 100% \n",
      "sphinx-3.3.1         | 1.5 MB    | ##################################### | 100% \n",
      "s3transfer-0.3.3     | 51 KB     | ##################################### | 100% \n",
      "toml-0.10.2          | 18 KB     | ##################################### | 100% \n",
      "pylint-2.6.0         | 446 KB    | ##################################### | 100% \n",
      "docutils-0.16        | 734 KB    | ##################################### | 100% \n",
      "astroid-2.4.2        | 297 KB    | ##################################### | 100% \n",
      "boto3-1.16.38        | 70 KB     | ##################################### | 100% \n",
      "torchvision-cpu-0.3. | 3.8 MB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 137 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch-cpu torchvision-cpu -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di bawah ini digunakan karena ketika langsung import modul, muncul <a href=\"https://stackoverflow.com/questions/41415629/importerror-no-module-named-tensorflow-python\">'no module named tensorflow'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.7 MB 3.0 kB/s  eta 0:00:01    |█▏                              | 14.6 MB 11.0 MB/s eta 0:00:35     |█████▊                          | 70.2 MB 59.2 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 70.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 38.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 51.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 57.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 44.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 459 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (45.2.0.post20200210)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 48.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.0.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (2.22.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.5.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 64.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.5)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 68.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=1b56f6381e0d84fc561ff38b38c7801662c0177d52634c73609c434747d0fe8e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=66621 sha256=edae00a774f82ec8135f542dbec8806a35a17e96bbf89ff34e8d09d5b6f28cbf\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built termcolor wrapt\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.179 has requirement botocore==1.19.19, but you'll have botocore 1.19.38 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awscli 1.18.179 has requirement docutils<0.16,>=0.10, but you'll have docutils 0.16 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast, six, numpy, keras-preprocessing, absl-py, wheel, flatbuffers, tensorflow-estimator, grpcio, astunparse, termcolor, tensorboard-plugin-wit, markdown, pyasn1-modules, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, wrapt, opt-einsum, typing-extensions, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.4 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 six-1.15.0 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wheel-0.36.2 wrapt-1.12.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "\n",
    "%matplotlib inline\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR) # can not running\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: Importing the Data\n",
    "\n",
    "The dataset is saved in a `data.csv` file. We will use `pandas` to take a look at some of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data tidak memiliki nama jadi perlu diberi nama <a href=\"https://www.kite.com/python/answers/how-to-set-column-names-when-importing-a-csv-into-a-pandas-dataframe-in-python#:~:text=Call%20pandas.,order%20they%20appear%20in%20names%20.\">'source'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column's name\n",
    "column_names = [\"serial\", \"date\", \"age\", \"distance\", \"stores\", \"latitude\", \"longitude\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>121</td>\n",
       "      <td>14264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>121</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>12029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>14157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial  date  age  distance  stores  latitude  longitude  price\n",
       "0       0  2009   21         9       6        84        121  14264\n",
       "1       1  2007    4         2       3        86        121  12032\n",
       "2       2  2016   18         3       7        90        120  13560\n",
       "3       3  2002   13         2       2        80        128  12029\n",
       "4       4  2014   25         5       8        81        122  14157"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', names = column_names) # can not running\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Check Missing Data\n",
    "\n",
    "It's a good practice to check if the data has any missing values. In real world data, this is quite common and must be taken care of before any data pre-processing or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serial       0\n",
       "date         0\n",
       "age          0\n",
       "distance     0\n",
       "stores       0\n",
       "latitude     0\n",
       "longitude    0\n",
       "price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Data Normalization\n",
    "\n",
    "We can make it easier for optimization algorithms to find minimas by normalizing the data before training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.181384</td>\n",
       "      <td>1.257002</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>-0.307212</td>\n",
       "      <td>-1.260799</td>\n",
       "      <td>0.350088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.350485</td>\n",
       "      <td>-1.319118</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.609312</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>-1.260799</td>\n",
       "      <td>-1.836486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.298598</td>\n",
       "      <td>-0.083410</td>\n",
       "      <td>-0.618094</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>1.590328</td>\n",
       "      <td>-1.576456</td>\n",
       "      <td>-0.339584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266643</td>\n",
       "      <td>-0.524735</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.927491</td>\n",
       "      <td>-1.572238</td>\n",
       "      <td>0.948803</td>\n",
       "      <td>-1.839425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.932135</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.981581</td>\n",
       "      <td>-1.255981</td>\n",
       "      <td>-0.945141</td>\n",
       "      <td>0.245266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       age  distance    stores  latitude  longitude     price\n",
       "0  0.015978  0.181384  1.257002  0.345224 -0.307212  -1.260799  0.350088\n",
       "1 -0.350485 -1.319118 -0.930610 -0.609312  0.325301  -1.260799 -1.836486\n",
       "2  1.298598 -0.083410 -0.618094  0.663402  1.590328  -1.576456 -0.339584\n",
       "3 -1.266643 -0.524735 -0.930610 -0.927491 -1.572238   0.948803 -1.839425\n",
       "4  0.932135  0.534444  0.006938  0.981581 -1.255981  -0.945141  0.245266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, 1:]\n",
    "df_norm = (df - df.mean())/df.std()\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2: Convert Label Value\n",
    "\n",
    "Because we are using normalized values for the labels, we will get the predictions back from a trained model in the same distribution. So, we need to convert the predicted values back to the original distribution if we want predicted prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14263\n"
     ]
    }
   ],
   "source": [
    "y_mean = df['price'].mean()\n",
    "y_std = df['price'].std()\n",
    "\n",
    "def convert_label_value(pred):\n",
    "    return int(pred * y_std + y_mean)\n",
    "\n",
    "print(convert_label_value(0.350088))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Select Features\n",
    "\n",
    "Make sure to remove the column __price__ from the list of features as it is the label and should not be used as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_norm.iloc[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.181384</td>\n",
       "      <td>1.257002</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>-0.307212</td>\n",
       "      <td>-1.260799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.350485</td>\n",
       "      <td>-1.319118</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.609312</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>-1.260799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.298598</td>\n",
       "      <td>-0.083410</td>\n",
       "      <td>-0.618094</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>1.590328</td>\n",
       "      <td>-1.576456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.266643</td>\n",
       "      <td>-0.524735</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.927491</td>\n",
       "      <td>-1.572238</td>\n",
       "      <td>0.948803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.932135</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.981581</td>\n",
       "      <td>-1.255981</td>\n",
       "      <td>-0.945141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       age  distance    stores  latitude  longitude\n",
       "0  0.015978  0.181384  1.257002  0.345224 -0.307212  -1.260799\n",
       "1 -0.350485 -1.319118 -0.930610 -0.609312  0.325301  -1.260799\n",
       "2  1.298598 -0.083410 -0.618094  0.663402  1.590328  -1.576456\n",
       "3 -1.266643 -0.524735 -0.930610 -0.927491 -1.572238   0.948803\n",
       "4  0.932135  0.534444  0.006938  0.981581 -1.255981  -0.945141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Select Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_norm.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.350088\n",
       "1   -1.836486\n",
       "2   -0.339584\n",
       "3   -1.839425\n",
       "4    0.245266\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Feature and Label Values\n",
    "\n",
    "We will need to extract just the numeric values for the features and labels as the TensorFlow model will expect just numeric values as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features array shape: (5000, 6)\n",
      "labels array shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "x_arr = x.values\n",
    "y_arr = y.values\n",
    "\n",
    "print('features array shape:', x_arr.shape)\n",
    "print('labels array shape:', y_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4: Train and Test Split\n",
    "\n",
    "We will keep some part of the data aside as a __test__ set. The model will not use this set during training and it will be used only for checking the performance of the model in trained and un-trained states. This way, we can make sure that we are going in the right direction with our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (4750, 6) (4750,)\n",
      "Test set: (250, 6) (250,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_arr, y_arr, test_size = 0.05, \n",
    "                                                   random_state=0)\n",
    "\n",
    "print('Training set:', x_train.shape, y_train.shape)\n",
    "print('Test set:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: Create the Model\n",
    "\n",
    "Let's write a function that returns an untrained model of a certain architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                70        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape = (6,), activation='relu'),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(5, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1: Model Training\n",
    "\n",
    "We can use an `EarlyStopping` callback from Keras to stop the model training if the validation loss stops decreasing for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "149/149 [==============================] - 1s 3ms/step - loss: 1.2363 - val_loss: 0.4727\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.2381\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.2480 - val_loss: 0.1863\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1985 - val_loss: 0.1651\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1529\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1639 - val_loss: 0.1509\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1609 - val_loss: 0.1459\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1545 - val_loss: 0.1468\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.1448\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1589 - val_loss: 0.1430\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1571 - val_loss: 0.1430\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1502 - val_loss: 0.1433\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1552 - val_loss: 0.1479\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1536 - val_loss: 0.1449\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1545 - val_loss: 0.1417\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1556 - val_loss: 0.1463\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1545 - val_loss: 0.1424\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1518 - val_loss: 0.1413\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1510 - val_loss: 0.1420\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1521 - val_loss: 0.1405\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1503 - val_loss: 0.1412\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1513 - val_loss: 0.1422\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1483 - val_loss: 0.1417\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1494 - val_loss: 0.1438\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 0s 1ms/step - loss: 0.1510 - val_loss: 0.1434\n"
     ]
    }
   ],
   "source": [
    "es_cb = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model = get_model()\n",
    "preds_on_untrained = model.predict(x_test)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                   validation_data = (x_test, y_test),\n",
    "                   epochs = 100,\n",
    "                   callbacks = [es_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2: Plot Training and Validation Loss\n",
    "\n",
    "Let's use the `plot_loss` helper function to take a look training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a5d8c9c0dab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_loss' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(history) # can not running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1: Plot Raw Predictions\n",
    "\n",
    "Let's use the `compare_predictions` helper function to compare predictions from the model when it was untrained and when it was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b55f413d7580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_on_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompare_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_on_untrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_on_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compare_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "preds_on_trained = model.predict(x_test)\n",
    "compare_predictions(preds_on_untrained, preds_on_trained, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2: Plot Price Predictions\n",
    "\n",
    "The plot for price predictions and raw predictions will look the same with just one difference: The x and y axis scale is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_untrained = [convert_label_value(y) for y in preds_on_untrained]\n",
    "price_trained = [convert_label_value(y) for y in preds_on_trained]\n",
    "price_test = [convert_label_value(y) for y in y_test]\n",
    "\n",
    "compare_predictions(price_untrained, price_trained, price_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
